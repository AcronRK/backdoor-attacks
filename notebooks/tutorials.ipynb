{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision.transforms import transforms\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda:0'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = transforms.ToTensor()\n",
    "\n",
    "batch_size = 8\n",
    "\n",
    "trainset = torchvision.datasets.FashionMNIST(root='../data', train=True, download=True, transform=transforms)\n",
    "testset = torchvision.datasets.FashionMNIST(root='../data', train=False, download=True, transform=transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ('T-shirt/top', 'Trouser/pants','Pullover shirt','Dress','Coat','Sandal',\n",
    "           'Shirt','Sneaker','Bag','Ankle boot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the train set into train and validation\n",
    "trainset, valset = torch.utils.data.random_split(trainset, [50000, 10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 10000, 10000)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "len(trainset), len(valset), len(testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of batches in the training set: 6250 \n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of batches in the training set: { int(len(trainset) / batch_size) } \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to iterate through the sets, we need to wrap them in a data loader\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "valloader = torch.utils.data.DataLoader(valset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 28, 28]), 9)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check images\n",
    "train_iter = iter(trainset)\n",
    "\n",
    "img, label = next(train_iter)\n",
    "\n",
    "img.shape, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NNet(nn.Module):\n",
    "    # what it has\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        \n",
    "        # input -> (1, 28, 28) Meaning a gray scale image with 1 channel\n",
    "        # output -> the depth?  \n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=256, kernel_size=3)\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3)\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(in_channels=512, out_channels=1024, kernel_size=2)\n",
    "        self.pool3 = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        self.flatten = nn.Flatten()\n",
    "        \n",
    "        self.fc1 = nn.Linear(in_features=4096, out_features=1024)\n",
    "        self.drop1 = nn.Dropout(p=0.3)\n",
    "        \n",
    "        self.fc2 = nn.Linear(in_features=1024, out_features=1024)\n",
    "        self.drop2 = nn.Dropout(p=0.3)\n",
    "        \n",
    "        self.out = nn.Linear(in_features=1024, out_features=10)\n",
    "        \n",
    "    # what to do \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool1(x)\n",
    "        \n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool2(x)\n",
    "        \n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = self.pool3(x)\n",
    "        \n",
    "        x = self.flatten(x)\n",
    "        \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.drop1(x)\n",
    "        \n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.drop2(x)\n",
    "        \n",
    "        x = self.out(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NNet(\n",
       "  (conv1): Conv2d(1, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv3): Conv2d(512, 1024, kernel_size=(2, 2), stride=(1, 1))\n",
       "  (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (fc1): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "  (drop1): Dropout(p=0.3, inplace=False)\n",
       "  (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (drop2): Dropout(p=0.3, inplace=False)\n",
       "  (out): Linear(in_features=1024, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# init the network\n",
    "net = NNet()\n",
    "net.to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input shape: torch.Size([8, 1, 28, 28])\n",
      "after network shape: torch.Size([8, 10])\n"
     ]
    }
   ],
   "source": [
    "# data is a tuple of input and label\n",
    "for i, data in enumerate(trainloader):\n",
    "    inputs, labels = data[0].to(device), data[1].to(device)\n",
    "    print(f\"input shape: {inputs.shape}\")\n",
    "    print(f\"after network shape: {net(inputs).shape}\")\n",
    "    break\n",
    "\n",
    "\n",
    "# Result: input shape: torch.Size([8, 1, 28, 28]);   torch.Size([8, 256, 26, 26])\n",
    "# 8 because we have a batch of 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of params: 8,536,074\n"
     ]
    }
   ],
   "source": [
    "num_params = 0\n",
    "for x in net.parameters():\n",
    "    num_params += len(torch.flatten(x))\n",
    "    \n",
    "print(f\"Number of params: {num_params:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimisers and loss fucntion\n",
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.utils.data.dataloader.DataLoader'>\n"
     ]
    }
   ],
   "source": [
    "print(type(trainloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(isinstance(optimizer, torch.optim.Optimizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch():\n",
    "    # set NN into training mode\n",
    "    net.train(True)\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    running_acc = 0.0\n",
    "    \n",
    "    # iterate over the data loader\n",
    "    for batch_index, data in enumerate(trainloader):\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs) # shape: [batch_size, 10]\n",
    "        correct = torch.sum(labels == torch.argmax(outputs, dim=1)).item()\n",
    "        \n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        \n",
    "        running_acc += correct / batch_size\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # print every 500 batches\n",
    "        if batch_index % 500 == 499:\n",
    "            running_loss_500_batches = running_loss / 500\n",
    "            running_acc_500_batches = (running_acc / 500) * 100\n",
    "            print(f\"Running loss: {running_acc_500_batches:.2f} - Running acc: {running_acc_500_batches:.2f}\")\n",
    "        \n",
    "            # reset running loss and acc\n",
    "            running_loss = 0.0\n",
    "            running_acc = 0.0\n",
    "    print()\n",
    "        \n",
    "\n",
    "def validate_epoch():\n",
    "    # set network to validation mode\n",
    "    net.train(False)\n",
    "    running_loss = 0.0\n",
    "    running_acc = 0.0\n",
    "    \n",
    "    for batch_index, data in enumerate(valloader):\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        \n",
    "        # dont worry about calculating gradients\n",
    "        with torch.no_grad():\n",
    "            outputs = net(inputs)\n",
    "            correct = torch.sum(labels == torch.argmax(outputs, dim=1)).item()\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            running_acc += correct / batch_size\n",
    "            running_loss += loss.item()\n",
    "        # calculate average loss and acc\n",
    "    avg_loss_all_batches = running_loss / len(valloader)\n",
    "    avg_acc_all_batches =( running_acc / len(valloader)) * 100\n",
    "    print(f\"Val loss: {avg_loss_all_batches:.2f} - Val acc: {avg_acc_all_batches:.2f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "Running loss: 95.97 - Running acc: 95.97\n",
      "Running loss: 95.78 - Running acc: 95.78\n",
      "Running loss: 95.93 - Running acc: 95.93\n",
      "Running loss: 95.40 - Running acc: 95.40\n",
      "Running loss: 95.25 - Running acc: 95.25\n",
      "Running loss: 95.93 - Running acc: 95.93\n",
      "Running loss: 96.17 - Running acc: 96.17\n",
      "Running loss: 95.43 - Running acc: 95.43\n",
      "Running loss: 95.17 - Running acc: 95.17\n",
      "Running loss: 94.70 - Running acc: 94.70\n",
      "Running loss: 94.90 - Running acc: 94.90\n",
      "Running loss: 94.83 - Running acc: 94.83\n",
      "\n",
      "Val loss: 0.27 - Val acc: 92.06\n",
      "\n",
      "Epoch: 1\n",
      "Running loss: 96.40 - Running acc: 96.40\n",
      "Running loss: 96.38 - Running acc: 96.38\n",
      "Running loss: 96.45 - Running acc: 96.45\n",
      "Running loss: 96.47 - Running acc: 96.47\n",
      "Running loss: 96.03 - Running acc: 96.03\n",
      "Running loss: 96.47 - Running acc: 96.47\n",
      "Running loss: 96.20 - Running acc: 96.20\n",
      "Running loss: 95.05 - Running acc: 95.05\n",
      "Running loss: 95.78 - Running acc: 95.78\n",
      "Running loss: 95.85 - Running acc: 95.85\n",
      "Running loss: 95.55 - Running acc: 95.55\n",
      "Running loss: 95.25 - Running acc: 95.25\n",
      "\n",
      "Val loss: 0.26 - Val acc: 92.51\n",
      "\n",
      "Epoch: 2\n",
      "Running loss: 96.75 - Running acc: 96.75\n",
      "Running loss: 97.25 - Running acc: 97.25\n",
      "Running loss: 96.45 - Running acc: 96.45\n",
      "Running loss: 96.38 - Running acc: 96.38\n",
      "Running loss: 96.15 - Running acc: 96.15\n",
      "Running loss: 96.78 - Running acc: 96.78\n",
      "Running loss: 96.85 - Running acc: 96.85\n",
      "Running loss: 95.78 - Running acc: 95.78\n",
      "Running loss: 96.53 - Running acc: 96.53\n",
      "Running loss: 96.43 - Running acc: 96.43\n",
      "Running loss: 96.15 - Running acc: 96.15\n",
      "Running loss: 96.10 - Running acc: 96.10\n",
      "\n",
      "Val loss: 0.28 - Val acc: 92.56\n",
      "\n",
      "Epoch: 3\n",
      "Running loss: 96.90 - Running acc: 96.90\n",
      "Running loss: 96.90 - Running acc: 96.90\n",
      "Running loss: 96.78 - Running acc: 96.78\n",
      "Running loss: 96.70 - Running acc: 96.70\n",
      "Running loss: 97.38 - Running acc: 97.38\n",
      "Running loss: 96.62 - Running acc: 96.62\n",
      "Running loss: 97.05 - Running acc: 97.05\n",
      "Running loss: 97.02 - Running acc: 97.02\n",
      "Running loss: 96.80 - Running acc: 96.80\n",
      "Running loss: 97.12 - Running acc: 97.12\n",
      "Running loss: 96.67 - Running acc: 96.67\n",
      "Running loss: 96.78 - Running acc: 96.78\n",
      "\n",
      "Val loss: 0.30 - Val acc: 92.38\n",
      "\n",
      "Epoch: 4\n",
      "Running loss: 97.35 - Running acc: 97.35\n",
      "Running loss: 97.78 - Running acc: 97.78\n",
      "Running loss: 97.28 - Running acc: 97.28\n",
      "Running loss: 97.08 - Running acc: 97.08\n",
      "Running loss: 97.25 - Running acc: 97.25\n",
      "Running loss: 97.32 - Running acc: 97.32\n",
      "Running loss: 97.28 - Running acc: 97.28\n",
      "Running loss: 97.32 - Running acc: 97.32\n",
      "Running loss: 97.38 - Running acc: 97.38\n",
      "Running loss: 97.40 - Running acc: 97.40\n",
      "Running loss: 97.00 - Running acc: 97.00\n",
      "Running loss: 96.83 - Running acc: 96.83\n",
      "\n",
      "Val loss: 0.35 - Val acc: 92.20\n",
      "\n",
      "Epoch: 5\n",
      "Running loss: 97.88 - Running acc: 97.88\n",
      "Running loss: 97.32 - Running acc: 97.32\n",
      "Running loss: 97.78 - Running acc: 97.78\n",
      "Running loss: 97.50 - Running acc: 97.50\n",
      "Running loss: 97.45 - Running acc: 97.45\n",
      "Running loss: 97.40 - Running acc: 97.40\n",
      "Running loss: 97.80 - Running acc: 97.80\n",
      "Running loss: 97.32 - Running acc: 97.32\n",
      "Running loss: 97.45 - Running acc: 97.45\n",
      "Running loss: 97.28 - Running acc: 97.28\n",
      "Running loss: 97.52 - Running acc: 97.52\n",
      "Running loss: 97.35 - Running acc: 97.35\n",
      "\n",
      "Val loss: 0.32 - Val acc: 92.30\n",
      "\n",
      "Epoch: 6\n",
      "Running loss: 98.55 - Running acc: 98.55\n",
      "Running loss: 97.70 - Running acc: 97.70\n",
      "Running loss: 98.02 - Running acc: 98.02\n",
      "Running loss: 97.78 - Running acc: 97.78\n",
      "Running loss: 97.80 - Running acc: 97.80\n",
      "Running loss: 97.90 - Running acc: 97.90\n",
      "Running loss: 97.45 - Running acc: 97.45\n",
      "Running loss: 98.22 - Running acc: 98.22\n",
      "Running loss: 97.95 - Running acc: 97.95\n",
      "Running loss: 97.58 - Running acc: 97.58\n",
      "Running loss: 97.52 - Running acc: 97.52\n",
      "Running loss: 97.30 - Running acc: 97.30\n",
      "\n",
      "Val loss: 0.30 - Val acc: 92.96\n",
      "\n",
      "Epoch: 7\n",
      "Running loss: 98.25 - Running acc: 98.25\n",
      "Running loss: 98.30 - Running acc: 98.30\n",
      "Running loss: 97.90 - Running acc: 97.90\n",
      "Running loss: 98.20 - Running acc: 98.20\n",
      "Running loss: 98.05 - Running acc: 98.05\n",
      "Running loss: 98.08 - Running acc: 98.08\n",
      "Running loss: 97.88 - Running acc: 97.88\n",
      "Running loss: 97.70 - Running acc: 97.70\n",
      "Running loss: 98.05 - Running acc: 98.05\n",
      "Running loss: 97.62 - Running acc: 97.62\n",
      "Running loss: 98.08 - Running acc: 98.08\n",
      "Running loss: 98.05 - Running acc: 98.05\n",
      "\n",
      "Val loss: 0.36 - Val acc: 92.55\n",
      "\n",
      "Epoch: 8\n",
      "Running loss: 98.35 - Running acc: 98.35\n",
      "Running loss: 97.92 - Running acc: 97.92\n",
      "Running loss: 98.38 - Running acc: 98.38\n",
      "Running loss: 97.92 - Running acc: 97.92\n",
      "Running loss: 97.80 - Running acc: 97.80\n",
      "Running loss: 98.35 - Running acc: 98.35\n",
      "Running loss: 98.38 - Running acc: 98.38\n",
      "Running loss: 97.82 - Running acc: 97.82\n",
      "Running loss: 98.28 - Running acc: 98.28\n",
      "Running loss: 98.28 - Running acc: 98.28\n",
      "Running loss: 98.22 - Running acc: 98.22\n",
      "Running loss: 97.88 - Running acc: 97.88\n",
      "\n",
      "Val loss: 0.46 - Val acc: 91.85\n",
      "\n",
      "Epoch: 9\n",
      "Running loss: 98.72 - Running acc: 98.72\n",
      "Running loss: 98.22 - Running acc: 98.22\n",
      "Running loss: 98.38 - Running acc: 98.38\n",
      "Running loss: 98.50 - Running acc: 98.50\n",
      "Running loss: 98.47 - Running acc: 98.47\n",
      "Running loss: 98.02 - Running acc: 98.02\n",
      "Running loss: 98.65 - Running acc: 98.65\n",
      "Running loss: 97.85 - Running acc: 97.85\n",
      "Running loss: 98.15 - Running acc: 98.15\n",
      "Running loss: 97.90 - Running acc: 97.90\n",
      "Running loss: 98.35 - Running acc: 98.35\n",
      "Running loss: 97.92 - Running acc: 97.92\n",
      "\n",
      "Val loss: 0.37 - Val acc: 92.16\n",
      "\n",
      "Finished!!!\n"
     ]
    }
   ],
   "source": [
    "# training loop\n",
    "\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch: {epoch}\")\n",
    "    train_epoch()\n",
    "    validate_epoch()\n",
    "    \n",
    "print(\"Finished!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "torch.save(net, '../models/fashnion_mnist.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
